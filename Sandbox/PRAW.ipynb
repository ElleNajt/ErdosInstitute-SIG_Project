{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd           \n",
    "import praw                   \n",
    "import re                     \n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "## acknowledgements\n",
    "'''\n",
    "https://stackoverflow.com/questions/48358837/pulling-reddit-comments-using-python-praw-and-creating-a-dataframe-with-the-resu\n",
    "https://www.reddit.com/r/redditdev/comments/2e2q2l/praw_downvote_count_always_zero/\n",
    "https://towardsdatascience.com/an-easy-tutorial-about-sentiment-analysis-with-deep-learning-and-keras-2bf52b9cba91\n",
    "\n",
    "For navigating pushshift: https://github.com/Watchful1/Sketchpad/blob/master/postDownloader.py\n",
    "\n",
    "# traffic = reddit.subreddit(subreddit).traffic() is not available to us, sadly.\n",
    "'''\n",
    "\n",
    "with open(\"../API.env\") as file:\n",
    "    exec(file.read())\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "  client_id = client_id,\n",
    "  client_secret = client_secret,\n",
    "  user_agent = user_agent\n",
    ")\n",
    "\n",
    "\n",
    "'''\n",
    "Some helper functions for the reddit API.\n",
    "'''\n",
    "\n",
    "def extract_num_rewards(awardings_data):\n",
    "    return sum( x[\"count\"] for x in awardings_data)\n",
    "\n",
    "def extract_data(submission, comments = False):\n",
    "    postlist = []\n",
    "\n",
    "    # extracts top level comments\n",
    "\n",
    "    if comments:\n",
    "        submission.comments.replace_more(limit=0)\n",
    "        for comment in submission.comments: \n",
    "            post = {} # put this here\n",
    "            post['author'] = comment.author\n",
    "            post['body'] = comment.body\n",
    "            post['awards'] = comment.all_awardings\n",
    "            post['score'] = comment.score\n",
    "            post['parent_id'] = comment.parent_id\n",
    "            post['id'] = comment.id\n",
    "\n",
    "            postlist.append(post)\n",
    "\n",
    "    content = {\n",
    "    \"title\" : submission.title,\n",
    "    \"self\" : submission.is_self,\n",
    "    \"text\" : submission.selftext,\n",
    "    \"comments\" : postlist,\n",
    "    \"author\" : submission.author,\n",
    "    \"name\" : submission.name,\n",
    "    \"time_created\" : submission.created_utc,\n",
    "    \"upvote_ratio\" : submission.upvote_ratio,\n",
    "    \"ups\" : submission.score, #this is the same as submission.ups,\n",
    "    \"downs\" : None,\n",
    "    \"awarders\" : submission.awarders, \n",
    "    \"awards\" : submission.all_awardings,\n",
    "    \"total_awards\" : None,\n",
    "    \"url\" : submission.url # Only relevant if not a self post\n",
    "    }\n",
    "    \n",
    "    content[\"total_awards\"] = extract_num_rewards(content[\"awards\"])\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Sample num_samples random submissions, and get the top num_samples submissions, and put them into dataframes.\n",
    "\n",
    "Opted instead to scrape the entire thing.\n",
    "'''\n",
    "\n",
    "def random_sample(num_samples, subreddit):\n",
    "    sample = []\n",
    "    for i in range(num_samples):\n",
    "        submission = reddit.subreddit(subreddit).random() \n",
    "        sample.append(extract_data(submission))\n",
    "    return(pd.DataFrame(sample))\n",
    "\n",
    "def sample(source):\n",
    "    submissions = []\n",
    "    for submission in source:\n",
    "        submissions.append(extract_data(submission))\n",
    "    print(f\"Got {len(submissions)} submissions. (This can be less than num_samples.)\")\n",
    "    return(pd.DataFrame(submissions))\n",
    "\n",
    "def top_sample(num_samples, subreddit):\n",
    "    return sample(reddit.subreddit(subreddit).top(limit=num_samples) )\n",
    "\n",
    "def rising_sample(num_samples, subreddit):\n",
    "    return sample(reddit.subreddit(subreddit).rising(limit=num_samples))\n",
    "\n",
    "def controversial_sample(num_samples, subreddit):\n",
    "    return sample(reddit.subreddit(subreddit).controversial(limit=num_samples) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 10 submissions. (This can be less than num_samples.)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_samples = 10\n",
    "subreddit ='wallstreetbets'\n",
    "\n",
    "\n",
    "\n",
    "#random_wsb = random_sample(num_samples, subreddit)\n",
    "#top_wsb = top_sample(num_samples,subreddit)\n",
    "#rising_wsb = rising_sample(num_samples, subreddit)\n",
    "#controversial_wsb = controversial_sample(num_samples, subreddit)\n",
    "\n",
    "#random_wsb.to_pickle(\"random_wsb.pkl\")\n",
    "#top_wsb.to_pickle(\"top_wsb.pkl\")\n",
    "#rising_wsb.to_pickle(\"rising_wsb.pkl\")\n",
    "#controversial_wsb.to_pickle(\"controversial_wsb.pkl\")\n",
    "\n",
    "# other commands here: https://praw.readthedocs.io/en/latest/code_overview/models/subreddit.html#praw.models.Subreddit.rising\n",
    "# NB: The subreddit stream option seems useful.\n",
    "# NB: There is also rising_random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = reddit.subreddit(subreddit).random() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.approved_at_utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comment_limit': 2048,\n",
       " 'comment_sort': 'confidence',\n",
       " 'id': 'n79brp',\n",
       " '_reddit': <praw.reddit.Reddit at 0x209b5dbb280>,\n",
       " '_fetched': True,\n",
       " '_comments_by_id': {'t1_gxbmyyu': Comment(id='gxbmyyu'),\n",
       "  't1_gxbwl4d': Comment(id='gxbwl4d'),\n",
       "  't1_gxcgbf4': Comment(id='gxcgbf4'),\n",
       "  't1_gxcl2le': Comment(id='gxcl2le'),\n",
       "  't1_gxd1p7e': Comment(id='gxd1p7e')},\n",
       " 'approved_at_utc': None,\n",
       " 'subreddit': Subreddit(display_name='wallstreetbets'),\n",
       " 'selftext': '',\n",
       " 'user_reports': [],\n",
       " 'saved': False,\n",
       " 'mod_reason_title': None,\n",
       " 'gilded': 0,\n",
       " 'clicked': False,\n",
       " 'title': '$3.4K gain from SPY calls, paper handed these but diamond handed some puts expiring on Monday ðŸ¤¡ ðŸ¤¡ðŸ¤¡',\n",
       " 'link_flair_richtext': [{'e': 'text', 't': 'Gain'}],\n",
       " 'subreddit_name_prefixed': 'r/wallstreetbets',\n",
       " 'hidden': False,\n",
       " 'pwls': 7,\n",
       " 'link_flair_css_class': 'profit',\n",
       " 'downs': 0,\n",
       " 'thumbnail_height': 55,\n",
       " 'top_awarded_type': None,\n",
       " 'parent_whitelist_status': 'some_ads',\n",
       " 'hide_score': False,\n",
       " 'name': 't3_n79brp',\n",
       " 'quarantine': False,\n",
       " 'link_flair_text_color': 'light',\n",
       " 'upvote_ratio': 0.86,\n",
       " 'author_flair_background_color': None,\n",
       " 'subreddit_type': 'public',\n",
       " 'ups': 24,\n",
       " 'total_awards_received': 0,\n",
       " 'media_embed': {},\n",
       " 'thumbnail_width': 140,\n",
       " 'author_flair_template_id': None,\n",
       " 'is_original_content': False,\n",
       " 'author_fullname': 't2_15wuks',\n",
       " 'secure_media': None,\n",
       " 'is_reddit_media_domain': True,\n",
       " 'is_meta': False,\n",
       " 'category': None,\n",
       " 'secure_media_embed': {},\n",
       " 'link_flair_text': 'Gain',\n",
       " 'can_mod_post': False,\n",
       " 'score': 24,\n",
       " 'approved_by': None,\n",
       " 'author_premium': True,\n",
       " 'thumbnail': 'image',\n",
       " 'edited': False,\n",
       " 'author_flair_css_class': None,\n",
       " 'author_flair_richtext': [],\n",
       " 'gildings': {},\n",
       " 'post_hint': 'image',\n",
       " 'content_categories': None,\n",
       " 'is_self': False,\n",
       " 'mod_note': None,\n",
       " 'created': 1620451271.0,\n",
       " 'link_flair_type': 'richtext',\n",
       " 'wls': 7,\n",
       " 'removed_by_category': None,\n",
       " 'banned_by': None,\n",
       " 'author_flair_type': 'text',\n",
       " 'domain': 'i.redd.it',\n",
       " 'allow_live_comments': False,\n",
       " 'selftext_html': None,\n",
       " 'likes': None,\n",
       " 'suggested_sort': 'confidence',\n",
       " 'banned_at_utc': None,\n",
       " 'url_overridden_by_dest': 'https://i.redd.it/lzxkl9q2mrx61.jpg',\n",
       " 'view_count': None,\n",
       " 'archived': False,\n",
       " 'no_follow': False,\n",
       " 'is_crosspostable': False,\n",
       " 'pinned': False,\n",
       " 'over_18': False,\n",
       " 'preview': {'images': [{'source': {'url': 'https://preview.redd.it/lzxkl9q2mrx61.jpg?auto=webp&s=1579c2dc679147b967cfca5ec19bbed56dba9737',\n",
       "     'width': 1234,\n",
       "     'height': 488},\n",
       "    'resolutions': [{'url': 'https://preview.redd.it/lzxkl9q2mrx61.jpg?width=108&crop=smart&auto=webp&s=2f10af447bc673d58384c0e26665d5de71d6ad99',\n",
       "      'width': 108,\n",
       "      'height': 42},\n",
       "     {'url': 'https://preview.redd.it/lzxkl9q2mrx61.jpg?width=216&crop=smart&auto=webp&s=04a5d240b7bc08876ef9265403bd7252c4447a30',\n",
       "      'width': 216,\n",
       "      'height': 85},\n",
       "     {'url': 'https://preview.redd.it/lzxkl9q2mrx61.jpg?width=320&crop=smart&auto=webp&s=3d2ef1bd2cd31c202c10733c15053655fc9057fb',\n",
       "      'width': 320,\n",
       "      'height': 126},\n",
       "     {'url': 'https://preview.redd.it/lzxkl9q2mrx61.jpg?width=640&crop=smart&auto=webp&s=63c356fe1df252c2721222c0ff15773115fe5850',\n",
       "      'width': 640,\n",
       "      'height': 253},\n",
       "     {'url': 'https://preview.redd.it/lzxkl9q2mrx61.jpg?width=960&crop=smart&auto=webp&s=71f7dd2602926eb75175d8bf936482c43ddb020e',\n",
       "      'width': 960,\n",
       "      'height': 379},\n",
       "     {'url': 'https://preview.redd.it/lzxkl9q2mrx61.jpg?width=1080&crop=smart&auto=webp&s=ad68f5391c668fdb83804bcf0fb9f0d4fbcf5827',\n",
       "      'width': 1080,\n",
       "      'height': 427}],\n",
       "    'variants': {},\n",
       "    'id': 'xoLkw6msVV1B2r0CQvgjcI7CTT0g_B7SPY59qwtElac'}],\n",
       "  'enabled': True},\n",
       " 'all_awardings': [],\n",
       " 'awarders': [],\n",
       " 'media_only': False,\n",
       " 'link_flair_template_id': '6bd9394c-0a95-11e9-82db-0eb3a11267a0',\n",
       " 'can_gild': False,\n",
       " 'spoiler': False,\n",
       " 'locked': False,\n",
       " 'author_flair_text': None,\n",
       " 'treatment_tags': [],\n",
       " 'visited': False,\n",
       " 'removed_by': None,\n",
       " 'num_reports': None,\n",
       " 'distinguished': None,\n",
       " 'subreddit_id': 't5_2th52',\n",
       " 'mod_reason_by': None,\n",
       " 'removal_reason': None,\n",
       " 'link_flair_background_color': '#349e48',\n",
       " 'is_robot_indexable': True,\n",
       " 'num_duplicates': 0,\n",
       " 'report_reasons': None,\n",
       " 'author': Redditor(name='Start155'),\n",
       " 'discussion_type': None,\n",
       " 'num_comments': 9,\n",
       " 'send_replies': True,\n",
       " 'media': None,\n",
       " 'contest_mode': False,\n",
       " 'author_patreon_flair': False,\n",
       " 'author_flair_text_color': None,\n",
       " 'permalink': '/r/wallstreetbets/comments/n79brp/34k_gain_from_spy_calls_paper_handed_these_but/',\n",
       " 'whitelist_status': 'some_ads',\n",
       " 'stickied': False,\n",
       " 'url': 'https://i.redd.it/lzxkl9q2mrx61.jpg',\n",
       " 'subreddit_subscribers': 10047617,\n",
       " 'created_utc': 1620422471.0,\n",
       " 'num_crossposts': 0,\n",
       " 'mod_reports': [],\n",
       " 'is_video': False,\n",
       " '_comments': <praw.models.comment_forest.CommentForest at 0x209bacad5b0>,\n",
       " 'flair': <praw.models.reddit.submission.SubmissionFlair at 0x209bacb3580>,\n",
       " 'mod': <praw.models.reddit.submission.SubmissionModeration at 0x209bacc6400>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<praw.models.reddit.submission.SubmissionFlair object at 0x00000209BACB3580>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(submission.flair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
