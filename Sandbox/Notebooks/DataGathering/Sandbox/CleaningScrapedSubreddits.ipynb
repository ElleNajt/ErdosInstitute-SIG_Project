{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1734e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd           \n",
    "import praw                   \n",
    "import re                     \n",
    "import datetime as dt\n",
    "import requests\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import timezone, datetime\n",
    "from matplotlib import pyplot\n",
    "\n",
    "'''\n",
    "\n",
    "The purpose of this code is to clean up the downloaded data frame, by converting html into text, \n",
    "and removing uninteresting columns.\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "def extract_text(s):\n",
    "    if s == None:\n",
    "        return None\n",
    "    soup = BeautifulSoup(s)\n",
    "    return soup.get_text()\n",
    "\n",
    "def date(created):\n",
    "    # Converts the timestamp to UTC time\n",
    "    return datetime.utcfromtimestamp(created)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3391b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "compiled = pd.DataFrame()\n",
    "\n",
    "directory = \"../Data/subreddits\"\n",
    "for filename in os.listdir(directory):\n",
    "    df = pd.read_pickle(os.path.join(directory, filename))\n",
    "    compiled = compiled.append(df)\n",
    "    \n",
    "compiled.reset_index()\n",
    "\n",
    "compiled\n",
    "\n",
    "\n",
    "\n",
    "compiled[\"selftext\"] = compiled[\"selftext_html\"].apply(extract_text)\n",
    "\n",
    "compiled[\"created_datetime_utc\"] = compiled[\"created_utc\"].apply(date)\n",
    "\n",
    "compiled.to_csv(\"../Data/subreddits.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52568fa1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__version__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-566b4646f4e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name '__version__' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2dfaa1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a67ff438",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subreddit in [\"WritingPrompts\"]: #\"Jokes\", \"TraditionalCurses\", \"TwoSentenceHorror\", \n",
    "    df = pd.read_pickle(\"../Data/subreddit_\" + subreddit + \"/full.pkl\")\n",
    "    df[\"selftext\"] = df[\"selftext_html\"].apply(extract_text)\n",
    "    df[\"created_datetime_utc\"] = df[\"created_utc\"].apply(date)\n",
    "    df.to_csv(\"../Data/subreddit_\" + subreddit + \"/full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7079db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c15680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
