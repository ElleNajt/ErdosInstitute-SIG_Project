{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e88e24a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33, 25], [1, 44], [29, 18], [23, 44], [45], [44], [22, 18], [12, 1], [22, 44], [23, 48, 25, 9]]\n",
      "tf.Tensor(\n",
      "[[33 25  0  0]\n",
      " [ 1 44  0  0]\n",
      " [29 18  0  0]\n",
      " [23 44  0  0]\n",
      " [45  0  0  0]\n",
      " [44  0  0  0]\n",
      " [22 18  0  0]\n",
      " [12  1  0  0]\n",
      " [22 44  0  0]\n",
      " [23 48 25  9]], shape=(10, 4), dtype=int32)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CB997E1DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2518 - accuracy: 0.5000\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.2621 - accuracy: 0.0000e+00WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n",
      " 10/100 [==>...........................] - 0s 7ms/step - loss: nan - accuracy: 0.4000   \n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.5000\n",
      "Accuracy: 50.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding_18/embeddings:0' shape=(50, 8) dtype=float32, numpy=\n",
       " array([[            nan,             nan,             nan,\n",
       "                     nan,             nan,             nan,\n",
       "                     nan,             nan],\n",
       "        [            nan,             nan,             nan,\n",
       "                     nan,             nan,             nan,\n",
       "                     nan,             nan],\n",
       "        [-4.43921238e-03, -3.41206416e-02,  1.02148652e-02,\n",
       "         -3.96571644e-02,  6.91390038e-03,  2.43119150e-03,\n",
       "          3.94488089e-02, -3.68946902e-02],\n",
       "        [-4.77595702e-02,  4.28549685e-02,  3.40427645e-02,\n",
       "         -2.61366367e-03, -2.29530819e-02, -3.02121397e-02,\n",
       "         -3.55172046e-02, -3.99884693e-02],\n",
       "        [-2.65065189e-02,  2.73002051e-02, -2.15772539e-03,\n",
       "         -2.23436002e-02, -7.70326704e-03,  8.53054598e-03,\n",
       "          1.56097449e-02, -2.52724886e-02],\n",
       "        [ 1.97380297e-02, -1.42700449e-02, -1.55620575e-02,\n",
       "          4.50800322e-02,  4.18409817e-02,  2.22367384e-02,\n",
       "          3.49428169e-02,  2.39050649e-02],\n",
       "        [-7.08063692e-03, -1.77623406e-02, -1.96560025e-02,\n",
       "          4.92835976e-02, -4.23126332e-02, -2.97788139e-02,\n",
       "          4.25375998e-04, -1.36857145e-02],\n",
       "        [-4.49949764e-02, -1.89185496e-02,  3.54432352e-02,\n",
       "          2.54038721e-03,  3.37765850e-02, -4.18524966e-02,\n",
       "         -1.61789730e-03,  4.76659276e-02],\n",
       "        [-9.86743718e-04, -3.53509784e-02,  3.38641517e-02,\n",
       "          2.75248401e-02,  5.61536476e-03,  1.90561078e-02,\n",
       "          2.15878226e-02,  1.57835335e-03],\n",
       "        [            nan,             nan,             nan,\n",
       "                     nan,             nan,             nan,\n",
       "                     nan,             nan],\n",
       "        [ 1.97945498e-02, -3.30626853e-02, -1.39495358e-02,\n",
       "          1.12546794e-02, -1.29731297e-02,  1.16799101e-02,\n",
       "         -3.53715569e-03, -4.00509126e-02],\n",
       "        [-4.67564240e-02, -2.04755310e-02, -1.03841908e-02,\n",
       "          3.10509689e-02, -1.88233014e-02, -4.13843766e-02,\n",
       "         -3.55851166e-02,  2.14412697e-02],\n",
       "        [            nan,             nan,             nan,\n",
       "                     nan,             nan,             nan,\n",
       "                     nan,             nan],\n",
       "        [ 2.22028531e-02,  1.04653724e-02, -3.13892961e-05,\n",
       "          1.44682415e-02,  7.80560821e-03, -2.72063166e-03,\n",
       "          2.91457810e-02, -1.29899159e-02],\n",
       "        [-3.62626687e-02, -5.91956452e-03, -2.66752392e-03,\n",
       "          4.60613519e-04,  2.56352164e-02,  9.40959528e-03,\n",
       "         -4.76877354e-02,  2.29076408e-02],\n",
       "        [ 3.65867727e-02,  7.78698921e-03, -1.72008872e-02,\n",
       "          4.98370863e-02, -6.82698563e-03, -2.31123101e-02,\n",
       "         -2.58882176e-02,  7.53881782e-03],\n",
       "        [ 2.66912617e-02, -1.69486515e-02,  3.22582237e-02,\n",
       "         -4.78328839e-02,  4.50947918e-02,  1.87974833e-02,\n",
       "          3.97029407e-02, -2.14229114e-02],\n",
       "        [ 4.88845743e-02,  2.45317258e-02, -2.16362607e-02,\n",
       "          4.99511883e-03, -4.82371934e-02,  2.52996348e-02,\n",
       "         -1.99187528e-02, -7.02649355e-03],\n",
       "        [            nan,             nan,             nan,\n",
       "                     nan,             nan,             nan,\n",
       "                     nan,             nan],\n",
       "        [ 2.76879556e-02, -1.79765709e-02, -2.00322997e-02,\n",
       "          1.31151117e-02, -3.25877815e-02, -4.66775782e-02,\n",
       "          1.18759982e-02,  1.27054751e-04],\n",
       "        [ 3.88239138e-02, -1.05587952e-02,  2.81085111e-02,\n",
       "          2.64906399e-02, -3.58985886e-02, -4.08803932e-02,\n",
       "         -3.56495753e-02, -4.23603132e-03],\n",
       "        [ 1.64085664e-02, -3.64921242e-03, -1.17593631e-02,\n",
       "          2.94028036e-02, -1.60058737e-02,  9.14076716e-03,\n",
       "         -4.38116677e-02, -3.33236828e-02],\n",
       "        [            nan,             nan,             nan,\n",
       "                     nan,             nan,             nan,\n",
       "                     nan,             nan],\n",
       "        [            nan,             nan,             nan,\n",
       "                     nan,             nan,             nan,\n",
       "                     nan,             nan],\n",
       "        [-7.81182200e-03,  2.25087143e-02,  9.53879207e-03,\n",
       "         -2.55683549e-02,  1.65870897e-02, -2.39381921e-02,\n",
       "          2.72433870e-02, -4.46355455e-02],\n",
       "        [            nan,             nan,             nan,\n",
       "                     nan,             nan,             nan,\n",
       "                     nan,             nan],\n",
       "        [ 4.73192669e-02, -4.03547287e-02,  4.46552895e-02,\n",
       "          7.10742548e-03, -1.48972757e-02, -4.31528799e-02,\n",
       "         -7.74048641e-03, -4.67939749e-02],\n",
       "        [ 3.69419567e-02,  3.28590982e-02, -9.99916345e-04,\n",
       "         -7.68878311e-03,  2.84842141e-02, -4.31632884e-02,\n",
       "          3.33597921e-02,  3.53998654e-02],\n",
       "        [-1.70809515e-02, -3.70397456e-02, -6.84745610e-05,\n",
       "         -1.93205010e-02, -4.80413809e-02,  3.65368761e-02,\n",
       "          2.75987722e-02, -1.81589834e-02],\n",
       "        [            nan,             nan,             nan,\n",
       "                     nan,             nan,             nan,\n",
       "                     nan,             nan],\n",
       "        [ 7.71883875e-03, -2.09255945e-02, -2.77110692e-02,\n",
       "         -2.58522872e-02,  4.70778607e-02,  7.22492859e-03,\n",
       "          1.21094286e-04, -3.73645648e-02],\n",
       "        [ 7.43335485e-03,  2.23454721e-02, -2.06058100e-03,\n",
       "         -3.06414850e-02, -7.86549971e-03,  4.30216081e-02,\n",
       "          4.42537777e-02, -4.97040264e-02],\n",
       "        [ 1.40856393e-02,  3.59061398e-02,  1.83111429e-03,\n",
       "         -1.59637555e-02, -3.12850624e-02,  2.78157480e-02,\n",
       "         -4.38429005e-02,  2.35874169e-02],\n",
       "        [            nan,             nan,             nan,\n",
       "                     nan,             nan,             nan,\n",
       "                     nan,             nan],\n",
       "        [-2.00354811e-02, -3.56493108e-02, -4.47436422e-03,\n",
       "          3.89667191e-02, -4.92393039e-02,  1.51810683e-02,\n",
       "         -1.43663511e-02,  2.33622082e-02],\n",
       "        [-3.74196842e-03,  2.49151029e-02, -2.60228403e-02,\n",
       "         -5.96795231e-03,  2.07324289e-02, -1.67060979e-02,\n",
       "         -4.44190875e-02, -4.90167253e-02],\n",
       "        [ 4.17500250e-02, -1.72803402e-02, -2.34254245e-02,\n",
       "          2.60459073e-02, -1.93753727e-02,  3.55529450e-02,\n",
       "          3.81443836e-02,  4.83262539e-03],\n",
       "        [ 2.69200914e-02, -3.99604551e-02, -3.80796082e-02,\n",
       "         -1.46751031e-02,  1.02444738e-03,  4.89097498e-02,\n",
       "          3.58548500e-02, -1.14899501e-02],\n",
       "        [-2.44319327e-02,  4.97232117e-02, -1.49508603e-02,\n",
       "         -5.92457131e-03,  1.20991953e-02,  4.19340618e-02,\n",
       "         -6.62224367e-03, -5.61287254e-03],\n",
       "        [-1.22177824e-02,  2.92123593e-02,  3.46845277e-02,\n",
       "         -1.43375620e-02,  7.59066269e-03,  3.81734036e-02,\n",
       "          2.42634527e-02, -4.32295464e-02],\n",
       "        [-5.52848727e-03,  4.52621616e-02, -2.58687865e-02,\n",
       "         -3.69176865e-02, -3.13328654e-02,  1.38563849e-02,\n",
       "         -1.71325803e-02, -1.69710405e-02],\n",
       "        [ 2.66513936e-02, -4.81458679e-02,  4.29614522e-02,\n",
       "         -3.19941416e-02, -1.52757652e-02,  4.83817980e-03,\n",
       "         -1.01181120e-03, -4.41219583e-02],\n",
       "        [-1.39518827e-03, -1.21346228e-02,  4.86513264e-02,\n",
       "          2.78927386e-04,  1.07066147e-02,  3.02209370e-02,\n",
       "         -4.07821164e-02, -4.77219224e-02],\n",
       "        [-3.99362817e-02,  2.13055946e-02, -1.27911195e-02,\n",
       "         -1.23787895e-02,  3.52894403e-02,  1.55360140e-02,\n",
       "          1.04572065e-02, -3.44722494e-02],\n",
       "        [            nan,             nan,             nan,\n",
       "                     nan,             nan,             nan,\n",
       "                     nan,             nan],\n",
       "        [            nan,             nan,             nan,\n",
       "                     nan,             nan,             nan,\n",
       "                     nan,             nan],\n",
       "        [ 4.97682728e-02, -1.55302994e-02, -2.78357621e-02,\n",
       "         -4.40049917e-04,  1.19510889e-02, -2.60898601e-02,\n",
       "         -2.42554545e-02, -1.31265037e-02],\n",
       "        [-4.46153060e-02, -1.84494853e-02, -1.69182904e-02,\n",
       "         -3.16346660e-02,  2.73023359e-02, -4.27599810e-02,\n",
       "         -8.28621536e-03, -2.72016879e-02],\n",
       "        [            nan,             nan,             nan,\n",
       "                     nan,             nan,             nan,\n",
       "                     nan,             nan],\n",
       "        [ 9.90890339e-03,  1.85392797e-04, -3.68411541e-02,\n",
       "          3.44315916e-03,  4.35243361e-02, -3.93939018e-03,\n",
       "         -3.78802791e-02,  3.93695496e-02]], dtype=float32)>,\n",
       " <tf.Variable 'dense_18/kernel:0' shape=(32, 1) dtype=float32, numpy=\n",
       " array([[nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan]], dtype=float32)>,\n",
       " <tf.Variable 'dense_18/bias:0' shape=(1,) dtype=float32, numpy=array([nan], dtype=float32)>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import SGD, Adam\n",
    "import numpy as np\n",
    "# define documents\n",
    "docs = ['Well done!',\n",
    "\t\t'Good work',\n",
    "\t\t'Great effort',\n",
    "\t\t'nice work',\n",
    "\t\t'Excellent!',\n",
    "\t\t'Weak',\n",
    "\t\t'Poor effort!',\n",
    "\t\t'not good',\n",
    "\t\t'poor work',\n",
    "\t\t'Could have done better.']\n",
    "# define class labels\n",
    "labels = tf.convert_to_tensor(np.array([1,1,1,1,1,0,0,0,0,0]))\n",
    "# integer encode the documents\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "padded_docs = tf.convert_to_tensor(padded_docs)\n",
    "print(padded_docs)\n",
    "# define the model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='mse', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=1)\n",
    "\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=1, verbose=1, steps_per_epoch = 100)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))\n",
    "model.weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "29cf0037",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-12a22a2b52d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "46600a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bcb83048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3adbd6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f26e4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33, 25,  0,  0],\n",
       "       [ 1, 44,  0,  0],\n",
       "       [29, 18,  0,  0],\n",
       "       [23, 44,  0,  0],\n",
       "       [45,  0,  0,  0],\n",
       "       [44,  0,  0,  0],\n",
       "       [22, 18,  0,  0],\n",
       "       [12,  1,  0,  0],\n",
       "       [22, 44,  0,  0],\n",
       "       [23, 48, 25,  9]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb399c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79a4d4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding_7/embeddings:0' shape=(50, 8) dtype=float32, numpy=\n",
       " array([[        nan,         nan,         nan,         nan,         nan,\n",
       "                 nan,         nan,         nan],\n",
       "        [        nan,         nan,         nan,         nan,         nan,\n",
       "                 nan,         nan,         nan],\n",
       "        [-0.01492083, -0.02976065, -0.01549443,  0.02936831, -0.00519624,\n",
       "          0.02345714, -0.00900381,  0.02160739],\n",
       "        [-0.01563947,  0.03499044,  0.04195911, -0.00820928,  0.01859761,\n",
       "          0.03502626, -0.0036392 , -0.04014714],\n",
       "        [ 0.0149253 ,  0.04101967, -0.03607244,  0.04328681, -0.01374529,\n",
       "          0.03189918, -0.01114007,  0.03640575],\n",
       "        [-0.00171951,  0.02650141,  0.03808595, -0.00699276,  0.02841487,\n",
       "          0.0461097 ,  0.01732432, -0.03013566],\n",
       "        [ 0.01084407,  0.00994591,  0.02445711,  0.0182477 , -0.03799838,\n",
       "         -0.00964101, -0.00401131, -0.00267639],\n",
       "        [ 0.01701654,  0.02725198, -0.00345892, -0.02969965,  0.0241455 ,\n",
       "          0.04750972, -0.03735339, -0.04808072],\n",
       "        [-0.01602503, -0.03827728,  0.03890152, -0.04977311,  0.02086605,\n",
       "         -0.04877513, -0.03628761,  0.03699613],\n",
       "        [ 0.02730309, -0.00498873, -0.02484289,  0.04427094, -0.01820049,\n",
       "         -0.02160077,  0.04893991, -0.0118364 ],\n",
       "        [ 0.02314508,  0.01344384, -0.04378508, -0.04884679,  0.00706965,\n",
       "          0.04277522, -0.02824948, -0.00900946],\n",
       "        [ 0.04280851, -0.02075508, -0.04471169, -0.00186379, -0.02124456,\n",
       "          0.03003253,  0.0153104 ,  0.04483509],\n",
       "        [-0.02578797,  0.0012396 ,  0.0428657 ,  0.0413432 ,  0.00334089,\n",
       "          0.02281393, -0.00159117,  0.01548227],\n",
       "        [-0.03530698,  0.04142955,  0.03819979,  0.01228844,  0.01282846,\n",
       "          0.02767457, -0.03017604, -0.04459661],\n",
       "        [        nan,         nan,         nan,         nan,         nan,\n",
       "                 nan,         nan,         nan],\n",
       "        [        nan,         nan,         nan,         nan,         nan,\n",
       "                 nan,         nan,         nan],\n",
       "        [ 0.04004825,  0.01220043, -0.02437711,  0.02108691, -0.03259562,\n",
       "         -0.02402639,  0.0492649 , -0.03510723],\n",
       "        [ 0.00913223,  0.02576098, -0.01832218, -0.04090074, -0.02703319,\n",
       "          0.0297201 , -0.03561305, -0.03501312],\n",
       "        [        nan,         nan,         nan,         nan,         nan,\n",
       "                 nan,         nan,         nan],\n",
       "        [ 0.0373907 ,  0.04750552,  0.02005212, -0.005538  , -0.0144232 ,\n",
       "          0.03006966, -0.01528049, -0.00053847],\n",
       "        [-0.02287502,  0.04084836,  0.03336406,  0.03832087, -0.0340681 ,\n",
       "         -0.03551905,  0.03360936,  0.01959285],\n",
       "        [ 0.02012372, -0.022856  ,  0.0133039 ,  0.03669969, -0.02598556,\n",
       "         -0.01083591, -0.03801621,  0.01977536],\n",
       "        [        nan,         nan,         nan,         nan,         nan,\n",
       "                 nan,         nan,         nan],\n",
       "        [-0.00111395, -0.03434458, -0.0146892 , -0.04835441, -0.04213538,\n",
       "         -0.00976796, -0.04786757,  0.04890836],\n",
       "        [ 0.03058938,  0.03388032,  0.03072545, -0.04943017,  0.036594  ,\n",
       "         -0.02216457,  0.02218447,  0.03533304],\n",
       "        [-0.00848784,  0.03052444,  0.0019227 , -0.01517782, -0.03088964,\n",
       "         -0.03112829,  0.03015217,  0.04290387],\n",
       "        [ 0.02322413,  0.01849366, -0.01265336,  0.02557946,  0.00031818,\n",
       "         -0.02227459,  0.01203178,  0.01061027],\n",
       "        [-0.00757455,  0.03070804, -0.04336528,  0.01425772,  0.02552934,\n",
       "          0.00395774,  0.00108527, -0.04527203],\n",
       "        [        nan,         nan,         nan,         nan,         nan,\n",
       "                 nan,         nan,         nan],\n",
       "        [ 0.00482636,  0.0247972 ,  0.0384875 ,  0.01440736, -0.00361142,\n",
       "          0.00386692,  0.0114597 ,  0.04578341],\n",
       "        [ 0.01340425, -0.01445693,  0.00869745,  0.00898732,  0.02330983,\n",
       "         -0.03504771, -0.03195572,  0.02502133],\n",
       "        [-0.00788905, -0.01574119, -0.00569023, -0.04995361, -0.01931515,\n",
       "         -0.04038993, -0.01577264,  0.00950966],\n",
       "        [        nan,         nan,         nan,         nan,         nan,\n",
       "                 nan,         nan,         nan],\n",
       "        [ 0.0490755 , -0.00960283, -0.00771695,  0.01472281,  0.04238688,\n",
       "          0.0173727 ,  0.01387395,  0.02104295],\n",
       "        [-0.0430054 ,  0.0083288 , -0.04804656,  0.04519386, -0.01395758,\n",
       "          0.00135771, -0.04910875, -0.00265039],\n",
       "        [-0.01110735, -0.04456115, -0.01607171,  0.03047117, -0.04641496,\n",
       "          0.02758049, -0.01958169, -0.00586386],\n",
       "        [-0.03555721,  0.00854256, -0.00362496, -0.02570852, -0.04992905,\n",
       "          0.03373976, -0.02692561, -0.02468565],\n",
       "        [        nan,         nan,         nan,         nan,         nan,\n",
       "                 nan,         nan,         nan],\n",
       "        [ 0.0414525 ,  0.00335147,  0.00067049,  0.02964444,  0.03337573,\n",
       "          0.01699761,  0.00275545,  0.00927992],\n",
       "        [ 0.02657079,  0.03715793,  0.03361073, -0.03583218, -0.0009892 ,\n",
       "         -0.01676713, -0.02567255,  0.01905341],\n",
       "        [ 0.04940393,  0.0360962 , -0.0355188 , -0.0242722 ,  0.04805428,\n",
       "         -0.02914571,  0.02839072,  0.00803803],\n",
       "        [-0.02879367,  0.04756993,  0.02733109, -0.04597671,  0.04468552,\n",
       "          0.03759744,  0.01485089, -0.00482269],\n",
       "        [ 0.0316003 ,  0.00347806, -0.01872148,  0.02204499, -0.00541921,\n",
       "         -0.0355489 , -0.03459451,  0.03123571],\n",
       "        [        nan,         nan,         nan,         nan,         nan,\n",
       "                 nan,         nan,         nan],\n",
       "        [        nan,         nan,         nan,         nan,         nan,\n",
       "                 nan,         nan,         nan],\n",
       "        [        nan,         nan,         nan,         nan,         nan,\n",
       "                 nan,         nan,         nan],\n",
       "        [ 0.00178249,  0.03316573, -0.04171998, -0.02496818,  0.0181313 ,\n",
       "         -0.02937049,  0.04533262, -0.02767861],\n",
       "        [ 0.0165428 , -0.04721848, -0.04426857,  0.02658567, -0.01011957,\n",
       "          0.045661  , -0.03137176,  0.01464805],\n",
       "        [ 0.03009478, -0.03155614,  0.02667919,  0.04536121,  0.04290236,\n",
       "          0.03594719, -0.00956105, -0.01581879],\n",
       "        [        nan,         nan,         nan,         nan,         nan,\n",
       "                 nan,         nan,         nan]], dtype=float32)>,\n",
       " <tf.Variable 'dense_7/kernel:0' shape=(32, 1) dtype=float32, numpy=\n",
       " array([[        nan],\n",
       "        [        nan],\n",
       "        [        nan],\n",
       "        [        nan],\n",
       "        [        nan],\n",
       "        [-0.14509112],\n",
       "        [        nan],\n",
       "        [-0.38114467],\n",
       "        [ 0.18396467],\n",
       "        [ 0.27180493],\n",
       "        [ 0.4118787 ],\n",
       "        [-0.05150861],\n",
       "        [        nan],\n",
       "        [        nan],\n",
       "        [ 0.18558604],\n",
       "        [-0.14348447],\n",
       "        [-0.1913433 ],\n",
       "        [ 0.23692876],\n",
       "        [ 0.02913056],\n",
       "        [ 0.3181948 ],\n",
       "        [ 0.30907938],\n",
       "        [ 0.33840153],\n",
       "        [ 0.20139259],\n",
       "        [-0.30555528],\n",
       "        [-0.07768404],\n",
       "        [ 0.21723855],\n",
       "        [ 0.31161255],\n",
       "        [-0.00350278],\n",
       "        [        nan],\n",
       "        [ 0.01801742],\n",
       "        [        nan],\n",
       "        [ 0.11255931]], dtype=float32)>,\n",
       " <tf.Variable 'dense_7/bias:0' shape=(1,) dtype=float32, numpy=array([nan], dtype=float32)>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f67dce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing import text\n",
    "tokenizer = text.Tokenizer(num_words=50)\n",
    "\n",
    "docs = ['Well done!',\n",
    "\t\t'Good work',\n",
    "\t\t'Great effort',\n",
    "\t\t'nice work',\n",
    "\t\t'Excellent!',\n",
    "\t\t'Weak',\n",
    "\t\t'Poor effort!',\n",
    "\t\t'not good',\n",
    "\t\t'poor work',\n",
    "\t\t'Could have done better.']\n",
    "\n",
    "\n",
    "tokenizer.fit_on_texts(docs)\n",
    "def prep_text(texts, tokenizer, max_sequence_length):\n",
    "    # Turns text into into padded sequences.\n",
    "    text_sequences = tokenizer.texts_to_sequences(texts)\n",
    "    return sequence.pad_sequences(text_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "sequences = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c96e82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x1cb9ca631f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd25001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML]",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
