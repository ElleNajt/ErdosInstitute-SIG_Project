{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69a1e28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "import xgboost as xgb\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c22f9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# For DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fa0c1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wsb = pd.read_csv('../Data/wsb_full.csv')\n",
    "#df = wsb.loc[wsb.removed_by_category.isnull()]\n",
    "#df.to_csv(\"../Data/wsb_not_null.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d0538b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/wsb_not_null.csv', usecols = ['id', 'title', 'selftext', 'ups', 'total_awards_received'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa2341a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "      <th>total_awards_received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.schaeffersresearch.com/content/ana...</td>\n",
       "      <td>Buy INTU - DD</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alright WSB,\\n\\nSo I recently came into about ...</td>\n",
       "      <td>New Years Challenge: 5K Make-it or Break-it</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I saw an older thread on it, curious who is st...</td>\n",
       "      <td>How many of you tism's are doing the UPRO/TMF ...</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>First day of legal weed in Illinois, passed by...</td>\n",
       "      <td>DD on pot stocks</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was going to tag this as technical, but sinc...</td>\n",
       "      <td>Markets are on the cusp of a correction and th...</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            selftext  \\\n",
       "0  https://www.schaeffersresearch.com/content/ana...   \n",
       "1  Alright WSB,\\n\\nSo I recently came into about ...   \n",
       "2  I saw an older thread on it, curious who is st...   \n",
       "3  First day of legal weed in Illinois, passed by...   \n",
       "4  I was going to tag this as technical, but sinc...   \n",
       "\n",
       "                                               title  ups  \\\n",
       "0                                      Buy INTU - DD    5   \n",
       "1        New Years Challenge: 5K Make-it or Break-it   50   \n",
       "2  How many of you tism's are doing the UPRO/TMF ...   27   \n",
       "3                                   DD on pot stocks    6   \n",
       "4  Markets are on the cusp of a correction and th...  173   \n",
       "\n",
       "   total_awards_received  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5690f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'title'\n",
    "#col = 'selftext' # this results in strings that are too long for the model ... TODO7 how to fix this?\n",
    "# maybe truncation is okay, ... maybe the first 400 and last time 112?\n",
    "\n",
    "df = df.dropna(subset = [col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a70812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c57b68d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa51bd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [2:07:00<00:00, 77.76s/it]   \n"
     ]
    }
   ],
   "source": [
    "batched_features = []\n",
    "\n",
    "def split_dataframe(df, chunk_size = 1000): \n",
    "    # https://stackoverflow.com/questions/17315737/split-a-large-pandas-dataframe\n",
    "    chunks = list()\n",
    "    num_chunks = len(df) // chunk_size + (1 if len(df) % chunk_size else 0)\n",
    "    for i in range(num_chunks):\n",
    "        chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "    return chunks\n",
    "\n",
    "cut_off = len(df) #200\n",
    "for batch in tqdm.tqdm(split_dataframe(df[:cut_off])):\n",
    "    # have to restrict into a smaller batch because my computer doesn't have enough memory...\n",
    "    \n",
    "    tokenized = batch[col].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "\n",
    "\n",
    "    max_len = 0\n",
    "    for i in tokenized.values:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "\n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "    attention_mask.shape\n",
    "\n",
    "\n",
    "    input_ids = torch.tensor(padded).type(torch.LongTensor) # have to cast to Longs\n",
    "    attention_mask = torch.tensor(attention_mask).type(torch.LongTensor)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    features = last_hidden_states[0][:,0,:].numpy()\n",
    "    batched_features.append(features)\n",
    "    \n",
    "features = np.vstack(batched_features)\n",
    "labels = df[:cut_off].ups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b3f7432",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(features).to_csv(\"bert_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8961f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bert_features'] = list(features)\n",
    "df.to_csv('wsb_with_bert.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258f18b2",
   "metadata": {},
   "source": [
    "Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d3fc19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd84ced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classification(features, bin_labels, model = LogisticRegression()):\n",
    "\n",
    "    \n",
    "    clf = DummyClassifier()\n",
    "    scores = cross_val_score(clf, features, bin_labels)\n",
    "    print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    \n",
    "    scores = cross_val_score(model, features, bin_labels)\n",
    "    print(\"Model classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc69a29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier score: 0.913 (+/- 0.00)\n",
      "Model classifier score: 0.923 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "test_classification(features, labels > 1, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e469ae4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier score: 0.758 (+/- 0.00)\n",
      "Model classifier score: 0.749 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "test_classification(features, df.total_awards_received >= 1, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2bbd40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bee4f169",
   "metadata": {},
   "source": [
    "Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cd68bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56ef54d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_regression(features, labels, model):\n",
    "    \n",
    "    #train_features, test_features, train_labels, test_labels = train_test_split(features, labels)\n",
    "    clf = DummyRegressor()\n",
    "\n",
    "    scores = cross_val_score(clf, features, labels)\n",
    "    print(\"Dummy regressor score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    \n",
    "    #model.fit(train_features, train_labels)\n",
    "    \n",
    "    scores = cross_val_score(model, features, labels)\n",
    "    print(\"Model regressor score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a40de05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()\n",
      "Dummy regressor score: -0.037 (+/- 0.06)\n",
      "Model regressor score: -0.120 (+/- 0.26)\n",
      "XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "             gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             random_state=2, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None)\n",
      "Dummy regressor score: -0.037 (+/- 0.06)\n",
      "Model regressor score: -0.850 (+/- 1.46)\n"
     ]
    }
   ],
   "source": [
    "for model in [LinearRegression(), xgb.XGBRegressor(random_state=2)]:\n",
    "    print(model)\n",
    "    test_regression(features, labels, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a284995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce019d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2224c0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3506955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c6e321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52b1e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304482da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec769f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af94f692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
