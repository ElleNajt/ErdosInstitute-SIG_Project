{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e690f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as pl\n",
    "import ot\n",
    "import ot.plot\n",
    "\n",
    "import pandas as pd\n",
    "import praw\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "import gensim.models\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "regex = re.compile('[^a-zA-Z ]')\n",
    "\n",
    "#@numba.jit # unfortunately this doesn't jit easily :(\n",
    "def tokenize(text):\n",
    "    # given a body of text, this splits into sentences, then processes each word in the sentence to remove\n",
    "    # non alphabetical characters... (? bad idea, what about users with numbers in their name)\n",
    "    # returns it as a list of lists of words, the format desired by gensims word2vec\n",
    "    \n",
    "    sentences = []\n",
    "    if type(text) == str:\n",
    "        for sentence in nltk.tokenize.sent_tokenize(text):\n",
    "            processed = [regex.sub('', word.lower()) for word in sentence.split(' ') ]\n",
    "            processed = [word for word in processed if word not in set( ['' ])]\n",
    "            sentences.append(processed)\n",
    "    return sentences\n",
    "\n",
    "def average_vector(text, model):\n",
    "    present_keys = [x for x in text if x in model.wv.key_to_index ]\n",
    "    if not present_keys:\n",
    "        return np.array([0] * len( model.wv[ model.wv.index_to_key[0]]))\n",
    "    return sum( [model.wv[x] for x in present_keys] ) /len(present_keys)\n",
    "\n",
    "def average_vector_paragraph(text, model):\n",
    "    if text == []:\n",
    "        return np.zeros(model.wv.vector_size)\n",
    "    return sum( average_vector(sentence, model)  for sentence in text )\n",
    "\n",
    "## Most similar posts?\n",
    "\n",
    "\n",
    "def similarity(vec_1, vec_2):\n",
    "    return sklearn.metrics.pairwise.cosine_similarity([vec_1], [vec_2])[0]\n",
    "\n",
    "def make_similarity_col(df, given_index):\n",
    "    given_vector = df['avg_vector'][given_index] \n",
    "    df['similarity'] = df['avg_vector'].apply( lambda x : similarity(x, given_vector))\n",
    "    \n",
    "# helper function for printing the most similar word vectors\n",
    "\n",
    "def sims(args, model):\n",
    "    for word, sim in model.wv.most_similar(**args, topn = 10):\n",
    "        print( f\"{word} - similarity {sim}\")    \n",
    "\n",
    "        \n",
    "        \n",
    "def train_w2v(tokenized_text):\n",
    "    # the train dataframe ot build the w2v model on\n",
    "    \n",
    "    corpus = []\n",
    "    for tokenized in tokenized_text:\n",
    "        corpus += tokenized\n",
    "\n",
    "    model = gensim.models.Word2Vec(sentences = corpus,  min_count=10, vector_size=300, epochs = 4)\n",
    "    #model_fasttext = gensim.models.FastText(sentences = corpus,  min_count=10, vector_size=200, epochs = 4)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def vectorize(df, model):\n",
    "    df['avg_vector'] = df['tokenized_title'].apply(lambda text : average_vector_paragraph(text, model)) \n",
    "    X = np.vstack(df['avg_vector'].to_numpy())\n",
    "    #df.concat(axis = 1, X)\n",
    "    return X\n",
    "\n",
    "def unpack_vectors(text, model):\n",
    "    vectors = []\n",
    "    for sentance in text:\n",
    "        for word in sentance:\n",
    "            if word in model.wv.key_to_index.keys():\n",
    "                vectors.append(model.wv[word])\n",
    "    return np.asarray(vectors)\n",
    "\n",
    "def cloudify(df, model):\n",
    "    df['point_cloud'] = df['tokenized_title'].apply(lambda text : unpack_vectors(text, model)) \n",
    "\n",
    "    return df\n",
    "\n",
    "def ot_distance(cloud_a, cloud_b):\n",
    "    n_a = len(cloud_a)\n",
    "    n_b = len(cloud_b)\n",
    "    a, b = np.ones((n_a,)) / n_a, np.ones((n_b,)) / n_b \n",
    "    M = ot.dist(cloud_a, cloud_b)\n",
    "    M /= M.max()\n",
    "    d = ot.emd2(a, b, M)\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae24b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/subreddit_WallStreetBets/otherdata/wsb_cleaned.csv\", nrows = 10000)\n",
    "\n",
    "df = df.dropna(subset = ['title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd3a9c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_title'] = df.title.apply(tokenize)\n",
    "#df['tokenized_selftext'] = df.selftext.apply(tokenize)\n",
    "model = train_w2v(df['tokenized_title']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83256637",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df = pd.DataFrame(model.wv.key_to_index.keys())\n",
    "corpus_df['vector'] = corpus_df[0].apply(lambda x : model.wv[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a189b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_counts = df.author.value_counts()\n",
    "#author_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "464e47eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['None',\n",
       " 'AutoModerator',\n",
       " 'fallouthong',\n",
       " 'MaxAds1',\n",
       " 'Sandvicheater',\n",
       " 'rawrtherapy',\n",
       " 'WSBConsensus',\n",
       " 'OldTrillionaire',\n",
       " 'thehandsoap',\n",
       " 'crossroadie666',\n",
       " 'bobbythebich',\n",
       " 'TripleBrain',\n",
       " 'bigbear0083',\n",
       " 'air_walks',\n",
       " 'Vinny32295',\n",
       " 'Ned_Flanderz',\n",
       " 'EnlargedOrgan',\n",
       " 'LiquidityMan',\n",
       " 'blaked_baller',\n",
       " 'jangles_mcdangles',\n",
       " 'eyedontgetjokes',\n",
       " 'StevenMcphearson',\n",
       " 'tombomassasin',\n",
       " 'charvo',\n",
       " 'vegaseller',\n",
       " 'AntinatalistPoet',\n",
       " 'Zer033x',\n",
       " 'alexstreerking203',\n",
       " 'Smackythefrogs',\n",
       " 'Ant0n61',\n",
       " 'stormwillpass',\n",
       " 'astafe',\n",
       " 'RoadhouseSwayz3',\n",
       " 'zachrf1',\n",
       " 'TheCreatorishere',\n",
       " 'Zmurray1996',\n",
       " 'omgoptions',\n",
       " 'Sakira-Cadman',\n",
       " 'sgalligan17',\n",
       " 'TimAppleBurner',\n",
       " 'oranguthang87',\n",
       " 'bencointl',\n",
       " 'spy400qqq300',\n",
       " 'Hadron90',\n",
       " 'Toasty_Man00',\n",
       " 'OGFlakah',\n",
       " 'narusik',\n",
       " 'TrendSpiderDan',\n",
       " '27onfire',\n",
       " 'bireland203',\n",
       " 'MostlyKelp',\n",
       " 'daddydickie',\n",
       " 'Stockbaron',\n",
       " 'DGAF0752',\n",
       " 'mcele311',\n",
       " 'DiffManyFold',\n",
       " 'opoopt',\n",
       " 'TheWorstTroll',\n",
       " 'philmacrack123',\n",
       " 'livestrong2209',\n",
       " 'triptamimico',\n",
       " 'Growth-oriented',\n",
       " 'Fatherthinger',\n",
       " 'MarketMovers19',\n",
       " 'GoergiDinkov',\n",
       " '1353-',\n",
       " 'SUP4oc',\n",
       " 'TheStreetProphet',\n",
       " 'notmichaelou',\n",
       " 'wsb_itch',\n",
       " 'debsman20',\n",
       " 'bigstonkguy',\n",
       " 'Nghtmare-Moon',\n",
       " 'Lagaru',\n",
       " 'jschall2',\n",
       " 'seaisthememes',\n",
       " 'gareddy2020',\n",
       " 'integratedcooling',\n",
       " 'CarlCarbonite',\n",
       " 'Yottahz',\n",
       " 'whatthef_rick',\n",
       " 'jok178',\n",
       " 'xbted9',\n",
       " 'datboiinawheelchair',\n",
       " 'lluxury',\n",
       " 'soAsian',\n",
       " 'neocoff',\n",
       " 'hermanhugh666',\n",
       " 'Drew1904',\n",
       " 'MCohen2019',\n",
       " 'dont-speak-everrr',\n",
       " 'david10121012',\n",
       " 'GermyBones',\n",
       " 'perfectentry1',\n",
       " '121518nine',\n",
       " 'kings_landing',\n",
       " 'rpmusictv',\n",
       " 'Theleniel',\n",
       " 'PocketRocketMarket',\n",
       " '96Nikko',\n",
       " 'Wannabetrader411',\n",
       " 'ControlPlusZ',\n",
       " 'j33tAy',\n",
       " 'TheyCallMeNoobxD',\n",
       " 'madmax_br5',\n",
       " 'xThe_Cool',\n",
       " 'coshibu',\n",
       " 'redbandit201',\n",
       " 'Litquidity88',\n",
       " 'S3__',\n",
       " 'Navdagoat',\n",
       " 'ironbassel',\n",
       " 'Drownt',\n",
       " 'achari01',\n",
       " 'myNeckar',\n",
       " 'jcw8',\n",
       " 'livesinadurian',\n",
       " 'ilevel239',\n",
       " 'Browningbeast',\n",
       " 'Vee91',\n",
       " 'haupt91',\n",
       " 'sinatra86',\n",
       " 'LuckLovesVirtue',\n",
       " 'MoneyBoy1997',\n",
       " 'winthropg',\n",
       " 'option-whisperer',\n",
       " 'My0nlyThrowaway',\n",
       " 'sanmitamin',\n",
       " 'toolfan21',\n",
       " 'Pathomator',\n",
       " 'Sheylaaa_xd',\n",
       " 'clutchmigiver',\n",
       " 'Influencer1980',\n",
       " 'natedoglit',\n",
       " 'serefsiz',\n",
       " 'Blahblahblurred',\n",
       " 'milehigheagle',\n",
       " 'FDsOnly',\n",
       " 'Justingamingdude',\n",
       " 'PutinIsMyDaddy1216',\n",
       " 'IpMedia',\n",
       " 'DelaRosaX',\n",
       " 'tinypenisguy4',\n",
       " 'IContiSonoInutili',\n",
       " 'nazarath6969',\n",
       " 'salukifire',\n",
       " 'fluffyevan',\n",
       " 'dmoeller05',\n",
       " 'Jburd6523',\n",
       " 'BedtimeTorture',\n",
       " 'DarkVybz',\n",
       " 'Shadypanda007',\n",
       " 'AdaptedApes',\n",
       " 'karlaxel2',\n",
       " 'Veliladon',\n",
       " 'Ass-Kickin_Chicken',\n",
       " 'Zekator',\n",
       " 'nikhil0416',\n",
       " 'trader011',\n",
       " 'Chewy910',\n",
       " 'AceOrigins',\n",
       " 'DumbRay',\n",
       " 'dbatchison',\n",
       " 'samuel-brubaker',\n",
       " 'BOWWSS',\n",
       " 'SebastianPatel',\n",
       " 'bullet69proof',\n",
       " 'Hello01234567890',\n",
       " 'Hercislife23',\n",
       " 'vmozara',\n",
       " 'HurricaneDorian321',\n",
       " 'guccitheta',\n",
       " 'balloonhi4000',\n",
       " 'Sexbomomb',\n",
       " 'NotZeke',\n",
       " 'Henry1502inc',\n",
       " 'sinbadz_ship',\n",
       " 'thewestcoastavenger',\n",
       " 'gdsmonster',\n",
       " 'grammerknewzi',\n",
       " 'BakerTheOptionMaker',\n",
       " 'Pooderson',\n",
       " 'redraiders2k9',\n",
       " 'walpo96',\n",
       " 'joelwhiteside76',\n",
       " 'pauliticiaan',\n",
       " 'nbmcucumber',\n",
       " 'OfficialJessyLara',\n",
       " 'Kmb91',\n",
       " 'pretender80',\n",
       " 'semicolin_',\n",
       " 'whiskieBoi',\n",
       " 'thunderwurst_noine',\n",
       " 'avyion12',\n",
       " 'hakimbomadadda',\n",
       " 'silverserpent67',\n",
       " 'GreyGoosez',\n",
       " 'SimpleJackNYBO',\n",
       " 'TheGUHboyyyyyy',\n",
       " 'MarcellusBoom',\n",
       " 'WindHero',\n",
       " 'Malverde116',\n",
       " 'DerpOfTheAges',\n",
       " 'GeezIjustdontknow',\n",
       " 'Prints-Charming',\n",
       " 'Jowemaha',\n",
       " 'Lucarioman7',\n",
       " 'SVXYstinks',\n",
       " 'RealStratBeckerYT',\n",
       " 'learningoptions',\n",
       " 'world_is_a_throwAway',\n",
       " 'unclerudy',\n",
       " 'aka5h',\n",
       " 'billwhiz',\n",
       " 'ZeusThunder369',\n",
       " 'EnemiesAllAround',\n",
       " 'IMeganNicole',\n",
       " 'antifrgl01',\n",
       " 'thetagangalwayswins',\n",
       " 'Weedstox101',\n",
       " 'cuzih8u',\n",
       " 'djst3venn',\n",
       " 'SmokyTree',\n",
       " 'dscg24',\n",
       " 'Espadinhaa',\n",
       " 'everythingorange9',\n",
       " 'OriginalFluff',\n",
       " 'optionseller',\n",
       " 'olara87',\n",
       " 'ynggekko',\n",
       " 'xesus2019',\n",
       " 'SSG11B',\n",
       " 'PregnantGhettoTeen',\n",
       " 'garthybooks22',\n",
       " 'BeetiF',\n",
       " 'lanier0814',\n",
       " 'Supersecretsauceboss',\n",
       " 'webulltrade',\n",
       " 'cdiamand',\n",
       " 'SpyroTheYoloDragon',\n",
       " 'GaniB',\n",
       " 'yeahnoworriesmate',\n",
       " 'jayp20122',\n",
       " 'Moldypieboy',\n",
       " 'petecam',\n",
       " 'The-Bannable',\n",
       " 'phoq5',\n",
       " 'cobimaestro',\n",
       " 'AUTOMATED_FUCK_BOT',\n",
       " 'Thatspellsgeraffes',\n",
       " 'NashAJ89',\n",
       " 'dungbat83',\n",
       " 'JustAnotherFKNSheep',\n",
       " 'goodthingshappening',\n",
       " '1sildurr',\n",
       " 'terataz',\n",
       " 'GedEllus214',\n",
       " 'bobbyneedslawadvice',\n",
       " 'FulfillmentHero',\n",
       " 'MrMilkwastaken',\n",
       " 'honkyblood',\n",
       " 'Ituglobal',\n",
       " 'TheMemehouseEffect',\n",
       " 'WhaleTrader1996',\n",
       " 'thecongocartel',\n",
       " 'WarPigs02',\n",
       " 'iamscyrus',\n",
       " 'JayPTQ',\n",
       " 'miccaahhh',\n",
       " 'Generalpluto3',\n",
       " 'official_wonderboy',\n",
       " 'iRnigger',\n",
       " 'tommy1010',\n",
       " 'Faissal_trades',\n",
       " 'iCorona01',\n",
       " 'rally_w_famly',\n",
       " 'onevmone',\n",
       " 'Titan04151912',\n",
       " 'danielsaid',\n",
       " 'DGKINGLOL',\n",
       " 'drewsmill',\n",
       " '66_Percent_Brad_Pitt',\n",
       " 'kilukila2707',\n",
       " 'stiveooo',\n",
       " 'joeywhiteaf',\n",
       " 'StringyBeans69',\n",
       " '__fritzz',\n",
       " 'Volsgamer81',\n",
       " 'Bigmealplantime',\n",
       " 'Ikemeki',\n",
       " 'i-only-buy-leaps',\n",
       " 'VoliorFPS',\n",
       " 'ignatztempotypo',\n",
       " 'DrGainTrain',\n",
       " 'Swipe4Swipes',\n",
       " 'violentindexs',\n",
       " 'NoFap_Allowed',\n",
       " 'computer_nerd_andy',\n",
       " 'lostallmyworth',\n",
       " 'NurseDaddy17',\n",
       " 'codex222',\n",
       " 'usrtea',\n",
       " 'thewhoadie',\n",
       " 'JustSomeNerdyDude',\n",
       " 'Ninety6ixx',\n",
       " 'ShiftBunny',\n",
       " 'mark000',\n",
       " 'the_jackness_monster',\n",
       " '9bitreddit',\n",
       " '_uCanDoBetterBrO_',\n",
       " 'montgola',\n",
       " 'AgitatedAntelopes',\n",
       " 'Micah3000',\n",
       " 'deltamoney',\n",
       " 'saveurBucks',\n",
       " 'upvoteguy5',\n",
       " 'K3rn3l_pAn1k',\n",
       " 'zevzev',\n",
       " 'kpthemaster',\n",
       " 'arbitrageisfreemoney',\n",
       " '3Roontgen',\n",
       " 'Andrew_the_giant',\n",
       " 'Kiiasert',\n",
       " 'DesignerFreedom',\n",
       " 'WeeklysOnly',\n",
       " 'usernamehorse',\n",
       " 'LittleDruck',\n",
       " 'EUG-EV-Enthusiast',\n",
       " 'ribru17',\n",
       " 'tsf_peso',\n",
       " 'SpeculatorScott',\n",
       " 'Church323',\n",
       " 'thekillerz99',\n",
       " '69deadlifts',\n",
       " 'VinnyMyWinny',\n",
       " 'raconteuring',\n",
       " 'Benski21',\n",
       " 'fstall303',\n",
       " 'Hendrix811',\n",
       " 'zsd99',\n",
       " 'lowkeyindivid',\n",
       " 'Spotalpha',\n",
       " 'Deonneon',\n",
       " 'celkon',\n",
       " 'Boomroomguy',\n",
       " 'donny1231992',\n",
       " 'NotToRedditty',\n",
       " 'bush_killed_epstein',\n",
       " 'BovineLover69',\n",
       " 'Jimbob67123',\n",
       " 'bainza',\n",
       " 'DudeWhoLived',\n",
       " 'krispyfriedyuca',\n",
       " 'YeetYourBroke',\n",
       " 'Gator432',\n",
       " 'decentralizor',\n",
       " 'TheCrazedGoat',\n",
       " 'artichoke2me',\n",
       " 'psytokine_storm',\n",
       " 'TheGloriousPlatitard',\n",
       " 'TheSkyPirate',\n",
       " 'franio04',\n",
       " 'IS_JOKE_COMRADE',\n",
       " 'Dankdeception',\n",
       " 'chris-c-thomas',\n",
       " 'n0pen0tme',\n",
       " 'onesagestudent',\n",
       " 'Skuggasveinn',\n",
       " 'BassMasterJDL',\n",
       " 'Xizad',\n",
       " 'Fausterion18',\n",
       " 'thetalljewish',\n",
       " 'funtimeshereonreddit',\n",
       " 'redbarebluebare',\n",
       " 'theoddman92',\n",
       " 'nachocheeze98',\n",
       " 'Rock_it_Scientist',\n",
       " 'controlyourlosses',\n",
       " 'Malo-Reconnaissance',\n",
       " 'chalkyspider',\n",
       " 'marioz64',\n",
       " 'Midgetfarm',\n",
       " 'Marnsy16',\n",
       " 'oze4',\n",
       " 'nitromicro',\n",
       " 'kwayne31',\n",
       " 'FrstdFlksAreGuhReat',\n",
       " 'cheeseburger-',\n",
       " 'mattgreenberg0',\n",
       " 'ztnabulsi',\n",
       " 'cjoh8',\n",
       " 'albinogoat',\n",
       " 'box4higher',\n",
       " 'jnguyen5301']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_than_one_post = list(author_counts [ author_counts > 2 ].index)\n",
    "more_than_one_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21419379",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = df[ df.author.isin(more_than_one_post)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f34194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "310ac79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "121518nine    [[-0.022375492, 0.19902197, 0.0023248703, 0.11...\n",
       "1353-         [[-0.023973137, 0.2047774, -0.0038402965, 0.12...\n",
       "1sildurr      [[-0.013164273, 0.1047017, 0.00011137097, 0.06...\n",
       "27onfire      [[-0.008771987, 0.07340773, -0.002343914, 0.04...\n",
       "3Roontgen     [[-0.008042797, 0.07422254, 0.0018973012, 0.04...\n",
       "                                    ...                        \n",
       "ynggekko      [[-0.02795647, 0.22810908, -0.0011223668, 0.12...\n",
       "zachrf1       [[-0.021291675, 0.1968608, 0.003938506, 0.1231...\n",
       "zevzev        [[-0.023973137, 0.2047774, -0.0038402965, 0.12...\n",
       "zsd99         [[-0.01478351, 0.16230886, 0.004318557, 0.0981...\n",
       "ztnabulsi     [[-0.007575758, 0.07291553, -0.0010454685, 0.0...\n",
       "Name: point_cloud, Length: 394, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compounded = cleaned[['tokenized_title', 'author']].groupby(\"author\").agg('sum')\n",
    "compounded.drop(labels = [\"None\", \"AutoModerator\"])\n",
    "clouded = cloudify(compounded, model)\n",
    "clouds = clouded.point_cloud\n",
    "clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad116fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dbe57f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dc2817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9be92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the 0th column out of 394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lnajt\\anaconda3\\envs\\ML\\lib\\site-packages\\ot\\lp\\__init__.py:421: UserWarning: Problem infeasible. Check that a and b are in the simplex\n",
      "  check_result(result_code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the 1th column out of 394\n",
      "Processing the 2th column out of 394\n",
      "Processing the 3th column out of 394\n"
     ]
    }
   ],
   "source": [
    "distances = np.zeros( shape= (len(clouds), len(clouds)) )\n",
    "for i in range(len(clouds)):\n",
    "    print(f\"Processing column {i} out of {len(clouds)}\")\n",
    "    for j in range(len(clouds)):\n",
    "        if i < j:\n",
    "            d = ot_distance(clouds.iloc[i], clouds.iloc[j])\n",
    "            distances[i,j] = d\n",
    "            distances[j,i] = d\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "75a3974e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0af3d374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9565fc73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e293cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5156c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc64363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ac4ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML]",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
