{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "332b3930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afdc632",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/wsb_full.csv')\n",
    "\n",
    "df = df.loc[df.removed_by_category.isnull()]\n",
    "\n",
    "col = 'title'\n",
    "df = df.dropna(subset = [col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fab0075",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = df[:5000][['title', 'selftext', 'ups']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99850509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aac59fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenized = batch_1[col].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1c666b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833ab6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7275bdae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449e4938",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2499cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08bc2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_ids = torch.tensor(padded).type(torch.LongTensor) # have to cast to Longs\n",
    "attention_mask = torch.tensor(attention_mask).type(torch.LongTensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407e5a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570fdf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = last_hidden_states[0][:,0,:].numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c780d8ee",
   "metadata": {},
   "source": [
    "Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e86e3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = batch_1.ups > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf01be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5200958",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec16cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762254a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier()\n",
    "\n",
    "scores = cross_val_score(clf, train_features, train_labels)\n",
    "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a453a4d3",
   "metadata": {},
   "source": [
    "Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acb76d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "clf = DummyRegressor()\n",
    "\n",
    "scores = cross_val_score(clf, train_features, train_labels)\n",
    "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c45d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c1a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = last_hidden_states[0][:,0,:].numpy()\n",
    "labels = batch_1.ups# > 1\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97d53b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3694af",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6067eca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41997eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a0766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "# Instantiate an XGBRegressor\n",
    "xgr = xgb.XGBRegressor(random_state=2)\n",
    "\n",
    "# Fit the classifier to the training set\n",
    "xgr.fit(train_features, train_labels)\n",
    "xgr.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e551c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9fa907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
