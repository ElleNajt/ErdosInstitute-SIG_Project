{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e8cf83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lnajt\\anaconda3\\envs\\ML\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import importlib\n",
    "\n",
    "import sys \n",
    "import os\n",
    "\n",
    "os.chdir(\"../Feature_Design\")\n",
    "from author_properties_transformers import author_influence\n",
    "from word2vec_transformers import conceptcluster, tokenizer\n",
    "import data_preprocessor\n",
    "os.chdir(\"../Regression\")\n",
    "\n",
    "from datetime import timezone, datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e414af5b",
   "metadata": {},
   "source": [
    "# Load and clean data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0327b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(subreddit, nrows = None):\n",
    "    df_messy = pd.read_csv(\"../Data/subreddit_\" + subreddit + \"/full.csv\", nrows = nrows)\n",
    "\n",
    "    # This removes weekly threads, and rows that have been deleted. Also removes posts that are not text posts.\n",
    "    # Creates more granular time features as well.\n",
    "    df_messy, award_cols = data_preprocessor.preprocess(df_messy)\n",
    "    \n",
    "    # TODO: this may be too severe of a cleanup.\n",
    "    \n",
    "\n",
    "    # make tokenized columns for the NLP methods\n",
    "    tokenizer().in_place(X = df_messy, cols = ['title', 'selftext'])\n",
    "\n",
    "    cols = [  'id',  'author', 'score', 'ups', 'downs', 'gilded', 'upvote_ratio', 'total_awards_received', 'num_comments', 'weektime', 'time_of_day', 'tokenized_title', 'tokenized_selftext'] + award_cols\n",
    "\n",
    "    df = df_messy[ cols]\n",
    "    return df, award_cols, df_messy\n",
    "\n",
    "\n",
    "for subreddit in [\"WallStreetBets\"]: #, \"TraditionalCurses\", \"WritingPrompts\", \"TwoSentenceHorror\", \"Jokes\"]:\n",
    "    #df, award_cols, df_messy = load(subreddit, nrows = None)\n",
    "    #df.to_csv(\"../Data/cleaned_\" + subreddit + \".csv\")\n",
    "\n",
    "    df = pd.read_csv(\"../Data/cleaned_\" + subreddit + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f762bf09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a363cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "award_cols = [col for col in list(df.columns) if col[:6] == \"award_\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9554fba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e0022c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e92862d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fd62674",
   "metadata": {},
   "source": [
    "## Create feature transformers for author features, time features, and nlp features.\n",
    "For details on the author and nlp transformers see, ../Feature_Design/author_properties_transformers and ../Feature_Design/word2vec_transformers\n",
    "\n",
    "Briefly, they do the following:\n",
    "\n",
    "1. Author influence calculates statistics of an authors upvote history from posts in the train set. \n",
    "\n",
    "2. Conceptcluster trains a word2vec model, then clusters the word vectors into concepts, and then counts the number of times each concept appear in the title or the selftext. Various options for the clustering approach are possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57b325b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_stat_features = FeatureUnion([('aggsum', author_influence(kind = 'sum')), \n",
    "                           ('aggmean', author_influence(kind = 'mean')), \n",
    "                           ('aggmedian', author_influence(kind = 'median')),\n",
    "                            ('aggcount', author_influence(kind = 'count')),\n",
    "                            ('aggupvote_ratio', author_influence(kind = 'beta_shrinkage_upvoteratio', prior = 'empirical_bayes')),\n",
    "                              #('aggpowerlaw', author_influence(kind = 'power_law')) # slows things down a lot      \n",
    "                           \n",
    "                           ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c22e3783",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_features = make_union( make_column_transformer(  \n",
    "                                (FunctionTransformer(lambda x : x), [\"weektime\", \"time_of_day\"] ),\n",
    "                                                   )            \n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e51d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_features = make_union( conceptcluster(  roughclustersize = 15 , verbose = False) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d6b891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1592c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_features = make_union ( author_stat_features, time_features, nlp_features )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a5a892",
   "metadata": {},
   "source": [
    "## Run a regression experiment:\n",
    "\n",
    "Trying to predict upvotes using those features. No luck so far. \n",
    "\n",
    "Comments: xgboost overfits, linear regression underfits.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e822eab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npipes = []\\nfor model in [LinearRegression(), xgb.XGBRegressor(random_state=2)]:\\n    X = df.drop(columns=['total_awards_received', 'num_comments'])\\n    y = df.ups\\n    pipes.append(run_experiment(model, X, y))\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def run_experiment(model, X, y):\n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=1)\n",
    "\n",
    "    print(\"working on\", model)\n",
    "\n",
    "    pipe = make_pipeline(all_features, model, verbose = True)\n",
    "    # all features drops the 'ups' category.\n",
    "    \n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    pipe.predict(X_test)\n",
    "\n",
    "    sns.scatterplot(x = pipe.predict(X_test), y = y_test)\n",
    "    plt.show()\n",
    "    sns.scatterplot(x = pipe.predict(X_train), y = y_train)\n",
    "    plt.show()\n",
    "    \n",
    "    scores = cross_val_score(pipe, X, y)\n",
    "    print(scores)\n",
    "    \n",
    "    return pipe\n",
    "\n",
    "'''\n",
    "pipes = []\n",
    "for model in [LinearRegression(), xgb.XGBRegressor(random_state=2)]:\n",
    "    X = df.drop(columns=['total_awards_received', 'num_comments'])\n",
    "    y = df.ups\n",
    "    pipes.append(run_experiment(model, X, y))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8894955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cc = pipes[0]['featureunion'].get_params()['featureunion-3'].get_params()['conceptcluster']\n",
    "#cc.corpus_df.prediction.value_counts().head(25)\n",
    "#cc.corpus_df[ cc.corpus_df.prediction == 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b42962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on DecisionTreeClassifier()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_experiment_classification(model, X, y):\n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=1)\n",
    "\n",
    "    print(\"working on\", model)\n",
    "\n",
    "    pipe = make_pipeline(all_features, model, verbose = True)\n",
    "    # all features drops the 'ups' category.\n",
    "    \n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    pipe.predict(X_test)\n",
    "\n",
    "    \n",
    "    clf = DummyClassifier()\n",
    "    scores = cross_val_score(clf, X, y)\n",
    "    print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    \n",
    "    scores = cross_val_score(pipe, X, y)\n",
    "    print(\"Model classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    \n",
    "    return pipe\n",
    "\n",
    "pipes = []\n",
    "for model in [tree.DecisionTreeClassifier(), LogisticRegression()]: #[LinearRegression(), xgb.XGBRegressor(random_state=2)]:\n",
    "    X = df.drop(columns=['total_awards_received', 'num_comments'] + award_cols)\n",
    "    y = df[\"award_Silver\"] > 0 \n",
    "    pipes.append(run_experiment_classification(model, X, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909443cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0d5075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63342199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8048639c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077db6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f30f976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31637fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949b9cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d196671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4775b2ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3427668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML]",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
